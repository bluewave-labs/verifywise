[
    {"model": "GPT-5.2 Pro", "score": 0.932},
    {"model": "GPT-5.2", "score": 0.924},
    {"model": "Gemini 3 Pro", "score": 0.919},
    {"model": "Gemini 3 Flash", "score": 0.904},
    {"model": "Grok-4 Heavy", "score": 0.884},
    {"model": "GPT-5 Medium", "score": 0.881},
    {"model": "GPT-5.1 High", "score": 0.881},
    {"model": "GPT-5.1 Instant", "score": 0.881},
    {"model": "GPT-5.1", "score": 0.881},
    {"model": "GPT-5.1 Thinking", "score": 0.881},
    {"model": "Grok-4", "score": 0.875},
    {"model": "GPT-5 High", "score": 0.873},
    {"model": "Claude Opus 4.5", "score": 0.87},
    {"model": "Gemini 2.5 Pro Preview 06-05", "score": 0.864},
    {"model": "GLM-4.7", "score": 0.857},
    {"model": "GPT-5", "score": 0.857},
    {"model": "Grok 4 Fast", "score": 0.857},
    {"model": "ERNIE 5.0", "score": 0.85},
    {"model": "Claude 3.7 Sonnet", "score": 0.848},
    {"model": "Grok-3", "score": 0.846},
    {"model": "Kimi K2-Thinking-0905", "score": 0.845},
    {"model": "ChatGPT-4o Latest", "score": 0.84},
    {"model": "Grok-3 Mini", "score": 0.84},
    {"model": "MiMo-V2-Flash", "score": 0.837},
    {"model": "Claude Sonnet 4.5", "score": 0.834},
    {"model": "o3", "score": 0.833},
    {"model": "Gemini 2.5 Pro", "score": 0.83},
    {"model": "Gemini 2.5 Flash", "score": 0.828},
    {"model": "DeepSeek-V3.2 (Thinking)", "score": 0.824},
    {"model": "GPT-5 mini", "score": 0.823},
    {"model": "o4-mini", "score": 0.814},
    {"model": "Qwen3-235B-A22B-Thinking-2507", "score": 0.811},
    {"model": "MiniMax M2.1", "score": 0.81},
    {"model": "GLM-4.6", "score": 0.81},
    {"model": "DeepSeek-R1-0528", "score": 0.81},
    {"model": "Claude Opus 4.1", "score": 0.809},
    {"model": "GPT OSS 120B High", "score": 0.809},
    {"model": "GPT OSS 120B", "score": 0.801},
    {"model": "DeepSeek-V3.2-Exp", "score": 0.799},
    {"model": "Claude Opus 4", "score": 0.796},
    {"model": "GLM-4.5", "score": 0.791},
    {"model": "o1-pro", "score": 0.79},
    {"model": "MiniMax M2", "score": 0.78},
    {"model": "o1", "score": 0.78},
    {"model": "Qwen3-235B-A22B-Instruct-2507", "score": 0.775},
    {"model": "o3-mini", "score": 0.772},
    {"model": "Qwen3-Next-80B-A3B-Thinking", "score": 0.772},
    {"model": "Llama 3.1 Nemotron Ultra 253B v1", "score": 0.7601},
    {"model": "Kimi K2 0905", "score": 0.758},
    {"model": "Claude Sonnet 4", "score": 0.754},
    {"model": "GLM-4.7-Flash", "score": 0.752},
    {"model": "Kimi K2 Instruct", "score": 0.751},
    {"model": "Kimi K2-Instruct-0905", "score": 0.751},
    {"model": "Nemotron 3 Nano (30B A3B)", "score": 0.75},
    {"model": "GLM-4.5-Air", "score": 0.75},
    {"model": "DeepSeek-V3.1", "score": 0.749},
    {"model": "Qwen3 VL 30B A3B Thinking", "score": 0.744},
    {"model": "GPT OSS 20B High", "score": 0.742},
    {"model": "Gemini 2.0 Flash Thinking", "score": 0.742},
    {"model": "ERNIE 4.5", "score": 0.74},
    {"model": "o1-preview", "score": 0.733},
    {"model": "DeepSeek R1 Zero", "score": 0.733},
    {"model": "Qwen3 VL 32B Thinking", "score": 0.731},
    {"model": "Claude Haiku 4.5", "score": 0.73},
    {"model": "Qwen3-Next-80B-A3B-Instruct", "score": 0.729},
    {"model": "GPT OSS 20B", "score": 0.715},
    {"model": "Ministral 3 (14B Reasoning 2512)", "score": 0.712},
    {"model": "GPT-5 nano", "score": 0.712},
    {"model": "Magistral Medium", "score": 0.708},
    {"model": "Qwen3 VL 30B A3B Instruct", "score": 0.704},
    {"model": "GPT-4o", "score": 0.701},
    {"model": "MiniMax M1 80K", "score": 0.7},
    {"model": "Qwen3 VL 8B Thinking", "score": 0.699},
    {"model": "Llama 4 Maverick", "score": 0.698},
    {"model": "GPT-4.5", "score": 0.695},
    {"model": "MiniMax M1 40K", "score": 0.692},
    {"model": "Qwen3 VL 32B Instruct", "score": 0.689},
    {"model": "Phi 4 Reasoning Plus", "score": 0.689},
    {"model": "DeepSeek-V3 0324", "score": 0.684},
    {"model": "Magistral Small 2506", "score": 0.6818},
    {"model": "Claude 3.5 Sonnet", "score": 0.672},
    {"model": "Ministral 3 (8B Reasoning 2512)", "score": 0.668},
    {"model": "Llama-3.3 Nemotron Super 49B v1", "score": 0.6667},
    {"model": "GPT-4.1", "score": 0.663},
    {"model": "Hermes 3 70B", "score": 0.661},
    {"model": "Qwen3 30B A3B", "score": 0.658},
    {"model": "Phi 4 Reasoning", "score": 0.658},
    {"model": "DeepSeek R1 Distill Llama 70B", "score": 0.652},
    {"model": "QwQ-32B-Preview", "score": 0.652},
    {"model": "QwQ-32B", "score": 0.652},
    {"model": "GPT-4.1 mini", "score": 0.65},
    {"model": "Gemini 2.5 Flash-Lite", "score": 0.646},
    {"model": "Qwen3 VL 4B Thinking", "score": 0.641},
    {"model": "Nemotron Nano 9B v2", "score": 0.64},
    {"model": "Gemini 2.0 Flash", "score": 0.621},
    {"model": "DeepSeek R1 Distill Qwen 32B", "score": 0.621},
    {"model": "Qwen3 Max", "score": 0.62},
    {"model": "o1-mini", "score": 0.6},
    {"model": "Claude 3.5 Sonnet", "score": 0.594},
    {"model": "DeepSeek R1 Distill Qwen 14B", "score": 0.591},
    {"model": "DeepSeek-V3", "score": 0.591},
    {"model": "Gemini 1.5 Pro", "score": 0.591},
    {"model": "Llama 4 Scout", "score": 0.572},
    {"model": "Phi 4", "score": 0.561},
    {"model": "Grok-2", "score": 0.56},
    {"model": "Llama 3.1 Nemotron Nano 8B V1", "score": 0.541},
    {"model": "GPT-4o", "score": 0.536},
    {"model": "Min  istral 3 (3B Reasoning 2512)", "score": 0.534},
    {"model": "Phi 4 Mini Reasoning", "score": 0.52},
    {"model": "Gemini 2.0 Flash-Lite", "score": 0.515},
    {"model": "Gemini 1.5 Flash", "score": 0.51},
    {"model": "Grok-2 mini", "score": 0.51},
    {"model": "Llama 3.1 405B Instruct", "score": 0.507},
    {"model": "Llama 3.3 70B Instruct", "score": 0.505},
    {"model": "Claude 3 Opus", "score": 0.504},
    {"model": "GPT-4.1 nano", "score": 0.503},
    {"model": "Qwen2.5 32B Instruct", "score": 0.495},
    {"model": "DeepSeek R1 Distill Qwen 7B", "score": 0.491},
    {"model": "DeepSeek R1 Distill Llama 8B", "score": 0.49},
    {"model": "Qwen2.5 72B Instruct", "score": 0.49},
    {"model": "Kimi K2 Base", "score": 0.481},
    {"model": "GPT-4 Turbo", "score": 0.48},
    {"model": "Qwen3 235B A22B", "score": 0.4747},
    {"model": "Nova Pro", "score": 0.469},
    {"model": "Llama 3.2 90B Instruct", "score": 0.467},
    {"model": "Mistral Small 3.2 24B Instruct", "score": 0.4613},
    {"model": "Qwen2.5 VL 32B Instruct", "score": 0.46},
    {"model": "Mistral Small 3.1 24B Instruct", "score": 0.4596},
    {"model": "Qwen2.5 14B Instruct", "score": 0.455},
    {"model": "Mistral Small 3 24B Instruct", "score": 0.453},
    {"model": "Mistral Large 3 (675B Instruct 2512)", "score": 0.439},
    {"model": "Mistral Large 3 (675B Instruct 2512 NVFP4)", "score": 0.439},
    {"model": "Mistral Large 3 (675B Instruct 2512 Eagle)", "score": 0.439},
    {"model": "Mistral Large 3 (675B Base)", "score": 0.439},
    {"model": "Qwen2 72B Instruct", "score": 0.424},
    {"model": "Gemma 3 27B", "score": 0.424},
    {"model": "Nova Lite", "score": 0.42},
    {"model": "Llama 3.1 70B Instruct", "score": 0.417},
    {"model": "Claude 3.5 Haiku", "score": 0.416},
    {"model": "Gemma 3 12B", "score": 0.409},
    {"model": "Claude 3 Sonnet", "score": 0.404},
    {"model": "Gemini Diffusion", "score": 0.404},
    {"model": "GPT-4o mini", "score": 0.402},
    {"model": "Nova Micro", "score": 0.4},
    {"model": "Gemini 1.5 Flash 8B", "score": 0.384},
    {"model": "Mistral Small 3.1 24B Base", "score": 0.375},
    {"model": "Jamba 1.5 Large", "score": 0.369},
    {"model": "Phi-3.5-MoE-instruct", "score": 0.368},
    {"model": "Qwen2.5 7B Instruct", "score": 0.364},
    {"model": "Grok-1.5", "score": 0.359},
    {"model": "GPT-4", "score": 0.357},
    {"model": "Mistral Small 3 24B Base", "score": 0.3437},
    {"model": "DeepSeek R1 Distill Qwen 1.5B", "score": 0.338},
    {"model": "Claude 3 Haiku", "score": 0.333},
    {"model": "Llama 3.2 11B Instruct", "score": 0.328},
    {"model": "Llama 3.2 3B Instruct", "score": 0.328},
    {"model": "Jamba 1.5 Mini", "score": 0.323},
    {"model": "Gemma 3 4B", "score": 0.308},
    {"model": "Qwen2.5-Omni-7B", "score": 0.308},
    {"model": "GPT-3.5 Turbo", "score": 0.308},
    {"model": "Phi-3.5-mini-instruct", "score": 0.304},
    {"model": "Llama 3.1 8B Instruct", "score": 0.304},
    {"model": "Gemini 1.0 Pro", "score": 0.279},
    {"model": "Qwen2 7B Instruct", "score": 0.253},
    {"model": "Phi 4 Mini", "score": 0.252},
    {"model": "Gemma 3n E2B Instructed LiteRT (Preview)", "score": 0.248},
    {"model": "Gemma 3n E2B Instructed", "score": 0.248},
    {"model": "Gemma 3n E4B Instructed", "score": 0.237},
    {"model": "Gemma 3n E4B Instructed LiteRT Preview", "score": 0.237},
    {"model": "Gemma 3 1B", "score": 0.192}
  ]
