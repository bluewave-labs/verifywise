{
    "generated_at": "2026-01-23T01:50:00.624752",
    "models": [
        {
            "rank": 1,
            "model": "GPT-5.1",
            "provider": "OpenAI",
            "verifywise_score": 53.8,
            "suites": {
                "instruction_following": 40.8,
                "rag_grounded_qa": 90.0,
                "coding_tasks": 52.5,
                "agent_workflows": 16.7,
                "safety_policy": 54.0
            },
            "tasks_passed": 24,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 92.5,
                "gpqa": 88.1,
                "gsm8k": null
            }
        },
        {
            "rank": 2,
            "model": "Claude Sonnet 4",
            "provider": "Anthropic",
            "verifywise_score": 53.1,
            "suites": {
                "instruction_following": 35.8,
                "rag_grounded_qa": 90.0,
                "coding_tasks": 48.8,
                "agent_workflows": 20.0,
                "safety_policy": 59.0
            },
            "tasks_passed": 26,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 90.4,
                "gpqa": 75.4,
                "gsm8k": 96.4
            }
        },
        {
            "rank": 3,
            "model": "Claude Sonnet 4.5",
            "provider": "Anthropic",
            "verifywise_score": 52.9,
            "suites": {
                "instruction_following": 33.3,
                "rag_grounded_qa": 90.0,
                "coding_tasks": 56.2,
                "agent_workflows": 20.0,
                "safety_policy": 52.0
            },
            "tasks_passed": 24,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 90.4,
                "gpqa": 83.4,
                "gsm8k": 96.4
            }
        },
        {
            "rank": 4,
            "model": "Claude Opus 4",
            "provider": "Anthropic",
            "verifywise_score": 51.9,
            "suites": {
                "instruction_following": 33.3,
                "rag_grounded_qa": 90.0,
                "coding_tasks": 48.8,
                "agent_workflows": 18.3,
                "safety_policy": 57.0
            },
            "tasks_passed": 25,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 86.8,
                "gpqa": 79.6,
                "gsm8k": 95.0
            }
        },
        {
            "rank": 5,
            "model": "o3-pro",
            "provider": "OpenAI",
            "verifywise_score": 51.9,
            "suites": {
                "instruction_following": 44.2,
                "rag_grounded_qa": 76.2,
                "coding_tasks": 46.2,
                "agent_workflows": 20.0,
                "safety_policy": 64.0
            },
            "tasks_passed": 26,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 86.9,
                "gpqa": 83.3,
                "gsm8k": null
            }
        },
        {
            "rank": 6,
            "model": "Claude Opus 4.1",
            "provider": "Anthropic",
            "verifywise_score": 51.2,
            "suites": {
                "instruction_following": 33.3,
                "rag_grounded_qa": 90.0,
                "coding_tasks": 48.8,
                "agent_workflows": 16.7,
                "safety_policy": 54.0
            },
            "tasks_passed": 25,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 86.8,
                "gpqa": 80.9,
                "gsm8k": 95.0
            }
        },
        {
            "rank": 7,
            "model": "Grok-4",
            "provider": "xAI",
            "verifywise_score": 50.3,
            "suites": {
                "instruction_following": 45.8,
                "rag_grounded_qa": 60.0,
                "coding_tasks": 52.5,
                "agent_workflows": 21.7,
                "safety_policy": 67.0
            },
            "tasks_passed": 28,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 87.5,
                "gpqa": 87.5,
                "gsm8k": 90.0
            }
        },
        {
            "rank": 8,
            "model": "DeepSeek R1 0528",
            "provider": "DeepSeek",
            "verifywise_score": 50.3,
            "suites": {
                "instruction_following": 24.2,
                "rag_grounded_qa": 88.8,
                "coding_tasks": 52.5,
                "agent_workflows": 20.0,
                "safety_policy": 57.0
            },
            "tasks_passed": 23,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 88.5,
                "gpqa": 81.0,
                "gsm8k": 95.1
            }
        },
        {
            "rank": 9,
            "model": "o3",
            "provider": "OpenAI",
            "verifywise_score": 50.1,
            "suites": {
                "instruction_following": 44.2,
                "rag_grounded_qa": 65.0,
                "coding_tasks": 52.5,
                "agent_workflows": 13.3,
                "safety_policy": 69.0
            },
            "tasks_passed": 26,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 86.9,
                "gpqa": 83.3,
                "gsm8k": null
            }
        },
        {
            "rank": 10,
            "model": "Claude Opus 4.5",
            "provider": "Anthropic",
            "verifywise_score": 48.0,
            "suites": {
                "instruction_following": 33.3,
                "rag_grounded_qa": 77.5,
                "coding_tasks": 48.8,
                "agent_workflows": 20.0,
                "safety_policy": 50.0
            },
            "tasks_passed": 24,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 86.8,
                "gpqa": 87.0,
                "gsm8k": 95.0
            }
        },
        {
            "rank": 11,
            "model": "o1-pro",
            "provider": "OpenAI",
            "verifywise_score": 47.5,
            "suites": {
                "instruction_following": 46.7,
                "rag_grounded_qa": 63.8,
                "coding_tasks": 33.8,
                "agent_workflows": 16.7,
                "safety_policy": 71.0
            },
            "tasks_passed": 26,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 91.8,
                "gpqa": 79.0,
                "gsm8k": 97.1
            }
        },
        {
            "rank": 12,
            "model": "GPT-5.2 Codex (xhigh)",
            "provider": "OpenAI",
            "verifywise_score": 46.1,
            "suites": {
                "instruction_following": 43.3,
                "rag_grounded_qa": 61.3,
                "coding_tasks": 52.5,
                "agent_workflows": 0.0,
                "safety_policy": 63.0
            },
            "tasks_passed": 26,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 92.5,
                "gpqa": 92.4,
                "gsm8k": null
            }
        },
        {
            "rank": 13,
            "model": "o4-mini",
            "provider": "OpenAI",
            "verifywise_score": 46.1,
            "suites": {
                "instruction_following": 45.8,
                "rag_grounded_qa": 51.3,
                "coding_tasks": 46.2,
                "agent_workflows": 10.0,
                "safety_policy": 74.0
            },
            "tasks_passed": 27,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 85.2,
                "gpqa": 81.4,
                "gsm8k": null
            }
        },
        {
            "rank": 14,
            "model": "o3-mini",
            "provider": "OpenAI",
            "verifywise_score": 44.4,
            "suites": {
                "instruction_following": 44.2,
                "rag_grounded_qa": 65.0,
                "coding_tasks": 23.8,
                "agent_workflows": 13.3,
                "safety_policy": 69.0
            },
            "tasks_passed": 23,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 86.9,
                "gpqa": 77.2,
                "gsm8k": null
            }
        },
        {
            "rank": 15,
            "model": "o1",
            "provider": "OpenAI",
            "verifywise_score": 42.5,
            "suites": {
                "instruction_following": 45.8,
                "rag_grounded_qa": 52.5,
                "coding_tasks": 30.0,
                "agent_workflows": 13.3,
                "safety_policy": 66.0
            },
            "tasks_passed": 24,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 91.8,
                "gpqa": 78.0,
                "gsm8k": 97.1
            }
        },
        {
            "rank": 16,
            "model": "GPT-5.2 (xhigh)",
            "provider": "OpenAI",
            "verifywise_score": 41.9,
            "suites": {
                "instruction_following": 40.8,
                "rag_grounded_qa": 48.8,
                "coding_tasks": 52.5,
                "agent_workflows": 10.0,
                "safety_policy": 50.0
            },
            "tasks_passed": 22,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 92.5,
                "gpqa": 92.4,
                "gsm8k": null
            }
        },
        {
            "rank": 17,
            "model": "GPT-5",
            "provider": "OpenAI",
            "verifywise_score": 39.7,
            "suites": {
                "instruction_following": 44.2,
                "rag_grounded_qa": 53.8,
                "coding_tasks": 48.8,
                "agent_workflows": 0.0,
                "safety_policy": 36.0
            },
            "tasks_passed": 19,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 92.5,
                "gpqa": 85.7,
                "gsm8k": null
            }
        },
        {
            "rank": 18,
            "model": "Gemini 3 Pro Preview",
            "provider": "Google",
            "verifywise_score": 34.7,
            "suites": {
                "instruction_following": 25.0,
                "rag_grounded_qa": 58.8,
                "coding_tasks": 41.2,
                "agent_workflows": 0.0,
                "safety_policy": 37.0
            },
            "tasks_passed": 15,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 85.9,
                "gpqa": 91.9,
                "gsm8k": 90.8
            }
        },
        {
            "rank": 19,
            "model": "GPT-5 Pro",
            "provider": "OpenAI",
            "verifywise_score": 33.5,
            "suites": {
                "instruction_following": 34.2,
                "rag_grounded_qa": 43.8,
                "coding_tasks": 48.8,
                "agent_workflows": 0.0,
                "safety_policy": 28.0
            },
            "tasks_passed": 17,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 92.5,
                "gpqa": 85.7,
                "gsm8k": null
            }
        },
        {
            "rank": 20,
            "model": "Gemini 2.5 Pro",
            "provider": "Google",
            "verifywise_score": 29.1,
            "suites": {
                "instruction_following": 24.2,
                "rag_grounded_qa": 52.5,
                "coding_tasks": 15.0,
                "agent_workflows": 3.3,
                "safety_policy": 43.0
            },
            "tasks_passed": 16,
            "tasks_evaluated": 44,
            "benchmarks": {
                "mmlu": 85.9,
                "gpqa": 83.0,
                "gsm8k": 90.8
            }
        }
    ],
    "score_info": {
        "name": "VerifyWise Application Score",
        "short_name": "Application Score",
        "description": "Measures how well LLMs perform on real-world enterprise application tasks, going beyond traditional academic benchmarks to evaluate practical utility.",
        "methodology": "Each model is evaluated on 44 carefully designed tasks across 5 evaluation suites. Tasks are scored as pass/fail based on strict criteria, and the final score is a weighted average.",
        "suites": {
            "instruction_following": {
                "name": "Instruction Following",
                "weight": 25,
                "description": "Tests the model's ability to follow complex, multi-step instructions precisely. Includes format constraints, conditional logic, and edge case handling.",
                "task_count": 12,
                "example_tasks": [
                    "Follow specific output formats",
                    "Handle conditional instructions",
                    "Multi-constraint satisfaction"
                ]
            },
            "rag_grounded_qa": {
                "name": "RAG Grounded QA",
                "weight": 25,
                "description": "Evaluates retrieval-augmented generation quality. Tests whether models can accurately answer questions using provided context without hallucinating.",
                "task_count": 8,
                "example_tasks": [
                    "Answer from context only",
                    "Cite sources correctly",
                    "Acknowledge knowledge gaps"
                ]
            },
            "coding_tasks": {
                "name": "Coding Tasks",
                "weight": 20,
                "description": "Assesses code generation, debugging, and explanation capabilities across multiple programming languages and complexity levels.",
                "task_count": 8,
                "example_tasks": [
                    "Generate working code",
                    "Debug existing code",
                    "Explain complex algorithms"
                ]
            },
            "agent_workflows": {
                "name": "Agent Workflows",
                "weight": 15,
                "description": "Tests agentic capabilities including tool use, multi-step planning, and autonomous task completion.",
                "task_count": 6,
                "example_tasks": [
                    "Multi-step tool use",
                    "Error recovery",
                    "Goal decomposition"
                ]
            },
            "safety_policy": {
                "name": "Safety & Policy",
                "weight": 15,
                "description": "Evaluates adherence to safety guidelines, refusal of harmful requests, and compliance with content policies.",
                "task_count": 10,
                "example_tasks": [
                    "Refuse harmful requests",
                    "Handle sensitive topics",
                    "Maintain appropriate boundaries"
                ]
            }
        },
        "scoring_formula": "Score = (IF \u00d7 0.25) + (RAG \u00d7 0.25) + (Coding \u00d7 0.20) + (Agent \u00d7 0.15) + (Safety \u00d7 0.15)",
        "evaluation_details": {
            "evaluator": "VerifyWise Evaluation Pipeline v2.0",
            "judge_model": "Human review + GPT-4.1 as automated judge",
            "evaluation_date": "January 2026",
            "reproducibility": "All evaluation prompts and scoring criteria are available in our open-source evaluation suite."
        }
    }
}