[
    {"model": "Kimi K2 0905", "score": 0.945},
    {"model": "Claude 3.5 Sonnet", "score": 0.937},
    {"model": "GPT-5", "score": 0.934},
    {"model": "Kimi K2 Instruct", "score": 0.933},
    {"model": "Qwen2.5-Coder 32B Instruct", "score": 0.927},
    {"model": "o1-mini", "score": 0.924},
    {"model": "Mistral Large 2", "score": 0.92},
    {"model": "Claude 3.5 Sonnet", "score": 0.92},
    {"model": "Qwen2.5 VL 32B Instruct", "score": 0.915},
    {"model": "GPT-4o", "score": 0.902},
    {"model": "Granite 3.3 8B Instruct", "score": 0.8973},
    {"model": "Granite 3.3 8B Base", "score": 0.8973},
    {"model": "Gemini Diffusion", "score": 0.896},
    {"model": "Llama 3.1 405B Instruct", "score": 0.89},
    {"model": "Nova Pro", "score": 0.89},
    {"model": "DeepSeek-V2.5", "score": 0.89},
    {"model": "Mistral Small 3.1 24B Instruct", "score": 0.8841},
    {"model": "Qwen2.5-Coder 7B Instruct", "score": 0.884},
    {"model": "Qwen2.5 32B Instruct", "score": 0.884},
    {"model": "Llama 3.3 70B Instruct", "score": 0.884},
    {"model": "Grok-2", "score": 0.884},
    {"model": "Claude 3.5 Haiku", "score": 0.881},
    {"model": "o1", "score": 0.881},
    {"model": "GPT-4.5", "score": 0.88},
    {"model": "Gemma 3 27B", "score": 0.878},
    {"model": "GPT-4o mini", "score": 0.872},
    {"model": "GPT-4 Turbo", "score": 0.871},
    {"model": "Qwen2.5 72B Instruct", "score": 0.866},
    {"model": "Qwen2 72B Instruct", "score": 0.86},
    {"model": "Grok-2 mini", "score": 0.857},
    {"model": "Gemma 3 12B", "score": 0.854},
    {"model": "Nova Lite", "score": 0.854},
    {"model": "Claude 3 Opus", "score": 0.849},
    {"model": "Mistral Small 3 24B Instruct", "score": 0.848},
    {"model": "Qwen2.5 7B Instruct", "score": 0.848},
    {"model": "Gemini 1.5 Pro", "score": 0.841},
    {"model": "Qwen2.5 14B Instruct", "score": 0.835},
    {"model": "Phi 4", "score": 0.826},
    {"model": "IBM Granite 4.0 Tiny Preview", "score": 0.824},
    {"model": "Nova Micro", "score": 0.811},
    {"model": "Codestral-22B", "score": 0.811},
    {"model": "Llama 3.1 70B Instruct", "score": 0.805},
    {"model": "Qwen2 7B Instruct", "score": 0.799},
    {"model": "Qwen2.5-Omni-7B", "score": 0.787},
    {"model": "Claude 3 Haiku", "score": 0.759},
    {"model": "Gemma 3n E4B Instructed", "score": 0.75},
    {"model": "Gemma 3n E4B Instructed LiteRT Preview", "score": 0.75},
    {"model": "Gemini 1.5 Flash", "score": 0.743},
    {"model": "Grok-1.5", "score": 0.741},
    {"model": "Claude 3 Sonnet", "score": 0.73},
    {"model": "Llama 3.1 8B Instruct", "score": 0.726},
    {"model": "Pixtral-12B", "score": 0.72},
    {"model": "Gemma 3 4B", "score": 0.713},
    {"model": "Phi-3.5-MoE-instruct", "score": 0.707},
    {"model": "GPT-3.5 Turbo", "score": 0.68},
    {"model": "GPT-4", "score": 0.67},
    {"model": "Gemma 3n E2B Instructed", "score": 0.665},
    {"model": "Gemma 3n E2B Instructed LiteRT (Preview)", "score": 0.665},
    {"model": "Phi-3.5-mini-instruct", "score": 0.628},
    {"model": "Gemma 2 27B", "score": 0.518},
    {"model": "Gemma 3 1B", "score": 0.415},
    {"model": "Gemma 2 9B", "score": 0.402},
    {"model": "Ministral 8B Instruct", "score": 0.348}
  ]
