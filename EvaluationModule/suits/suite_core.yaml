version: 1
suite_name: core
description: "Core quality gate thresholds for DeepEval metrics. Set thresholds as needed; null skips a check."
metrics:
  "Knowledge Retention":
    comparison: gte
    thresholds:
      average_score: 0.99
  "Bias":
    comparison: lte
    thresholds:
      average_score: 0.7
  "Tonality":
    comparison: gte
    thresholds:
      average_score: 0.8
  "Coherence":
    comparison: gte
    thresholds:
      average_score: 0.9
  "Conversation Relevancy":
    comparison: gte
    thresholds:
      average_score: 0.87
  "Role Adherence":
    comparison: gte
    thresholds:
      average_score: 0.99
  "Conversation Completeness":
    comparison: gte
    thresholds:
      average_score: 0.88
  "Toxicity":
    comparison: lte
    thresholds:
      average_score: 0.8